{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2094f1f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:22.949887Z",
     "iopub.status.busy": "2024-01-24T06:27:22.949334Z",
     "iopub.status.idle": "2024-01-24T06:27:23.885307Z",
     "shell.execute_reply": "2024-01-24T06:27:23.883725Z"
    },
    "papermill": {
     "duration": 0.946512,
     "end_time": "2024-01-24T06:27:23.888430",
     "exception": false,
     "start_time": "2024-01-24T06:27:22.941918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c39a2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:23.901548Z",
     "iopub.status.busy": "2024-01-24T06:27:23.900911Z",
     "iopub.status.idle": "2024-01-24T06:27:37.084749Z",
     "shell.execute_reply": "2024-01-24T06:27:37.081971Z"
    },
    "papermill": {
     "duration": 13.193734,
     "end_time": "2024-01-24T06:27:37.087767",
     "exception": false,
     "start_time": "2024-01-24T06:27:23.894033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47340it [00:04, 10097.81it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv') # loading training data\n",
    "data = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    temp = ast.literal_eval(row['tagged_sentence'])\n",
    "    sent = []\n",
    "    for word, tag in temp:\n",
    "        if (len(sent)==0):\n",
    "            sent.append((word.lower(), tag))\n",
    "        else:\n",
    "            sent.append((word, tag))\n",
    "    data.append(list(reversed(sent))) # changing data-type of entries from 'str' to 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9199fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_test split\n",
    "random.shuffle(data)\n",
    "num_samples = len(data)\n",
    "# train_data = data[:int(num_samples*0.8)]\n",
    "# val_data = data[int(num_samples*0.8):]\n",
    "train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7d94230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:37.124238Z",
     "iopub.status.busy": "2024-01-24T06:27:37.123832Z",
     "iopub.status.idle": "2024-01-24T06:27:37.748538Z",
     "shell.execute_reply": "2024-01-24T06:27:37.746966Z"
    },
    "papermill": {
     "duration": 0.645769,
     "end_time": "2024-01-24T06:27:37.751054",
     "exception": false,
     "start_time": "2024-01-24T06:27:37.105285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [00:00, 21770.27it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test_small.csv') # loading test data\n",
    "test_data = {}\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    test_data[row['id']] = ast.literal_eval(row['untagged_sentence']) # changing data-type of entries from 'str' to 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb38a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store words set, tags set as present in original corpus\n",
    "words = set()\n",
    "for sent in train_data:\n",
    "    for word, _ in sent:\n",
    "        words.add(word)\n",
    "words =list(words)\n",
    "num_words = len(words)\n",
    "word2idx = {word: i for i, word in enumerate(words)}\n",
    "\n",
    "# store word cnts\n",
    "word_cnts = np.zeros(num_words)\n",
    "for sent in train_data:\n",
    "    for word, _ in sent:\n",
    "        word_cnts[word2idx[word]]+=1\n",
    "        \n",
    "# define cutoff\n",
    "cutoff = 2\n",
    "unk = \"UNK\"\n",
    "default =\"NN\"\n",
    "eps = 0\n",
    "# re define words\n",
    "new_words = set()\n",
    "for i in range(num_words):\n",
    "    if (word_cnts[i]>cutoff):\n",
    "        new_words.add(words[i])\n",
    "    else:\n",
    "        new_words.add(unk)\n",
    "words = new_words\n",
    "# define \n",
    "tags = set()\n",
    "for sent in train_data:\n",
    "    for word, tag in sent:\n",
    "        # if word not in words:\n",
    "        #     tags.add(unk)\n",
    "        # else:\n",
    "        #     tags.add(tag)\n",
    "        tags.add(tag)\n",
    "\n",
    "num_words = len(words)\n",
    "words = list(words)\n",
    "word2idx = {word: i for i, word in enumerate(words)}\n",
    "\n",
    "tags.add(unk)\n",
    "num_tags = len(tags)\n",
    "tags =list(tags)\n",
    "tag2idx = {tag: i for i, tag in enumerate(tags)}\n",
    "\n",
    "assert(unk in words)\n",
    "# assert(unk in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c93a2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique words\n",
    "words_tags_dict = dict()\n",
    "\n",
    "for sent in train_data:\n",
    "    for word, tag in sent:\n",
    "        if word not in words_tags_dict:\n",
    "            words_tags_dict[word] = set()\n",
    "        words_tags_dict[word].add(tag)\n",
    "        \n",
    "unique_tag_words = []\n",
    "for word in words_tags_dict:\n",
    "    if (len(words_tags_dict[word]) == 1):\n",
    "        unique_tag_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c8a4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_prefs = dict()\n",
    "candidate_suffs = dict()\n",
    "\n",
    "def get_prefs(word):\n",
    "    n = len(word)\n",
    "    # take upto 5 \n",
    "    if (n<6):\n",
    "        word = word+(6-n)*(\" \")\n",
    "    return [word[:1], word[:2], word[:3], word[:4], word[:5], word[:6]]\n",
    "\n",
    "def get_suffs(word):\n",
    "    n = len(word)\n",
    "    # take upto 5 \n",
    "    if (n<6):\n",
    "        word = (6-n)*(\" \")+word\n",
    "    return [word[-1:], word[-2:], word[-3:], word[-4:], word[-5:], word[-6:]]\n",
    "\n",
    "for word in unique_tag_words:\n",
    "# for word in words:\n",
    "    prefs = get_prefs(word)\n",
    "    for pref in prefs:\n",
    "        if pref not in candidate_prefs:\n",
    "            candidate_prefs[pref] = dict()\n",
    "        # for tag in list(words_tags_dict[word]):\n",
    "        tag = list(words_tags_dict[word])[0]\n",
    "        if tag not in candidate_prefs[pref]:\n",
    "            candidate_prefs[pref][tag] = 0\n",
    "        candidate_prefs[pref][tag]+=1\n",
    "    \n",
    "    suffs = get_suffs(word)\n",
    "    for suff in suffs:\n",
    "        if suff not in candidate_suffs:\n",
    "            candidate_suffs[suff] = dict()\n",
    "        tag = list(words_tags_dict[word])[0]\n",
    "        if tag not in candidate_suffs[suff]:\n",
    "            candidate_suffs[suff][tag] = 0\n",
    "        candidate_suffs[suff][tag]+=1\n",
    "        \n",
    "pref_scores = dict()\n",
    "suff_scores = dict()\n",
    "\n",
    "for pref in candidate_prefs:\n",
    "    mx = 0\n",
    "    sm = 0\n",
    "    mx_tag = None\n",
    "    for tag, cnt in candidate_prefs[pref].items():\n",
    "        if mx < cnt:\n",
    "            mx_tag = tag\n",
    "            mx = cnt\n",
    "        sm += cnt\n",
    "    score = mx/sm\n",
    "    pref_scores[pref] = score, mx_tag\n",
    "\n",
    "for suff in candidate_suffs:\n",
    "    mx = 0\n",
    "    sm = 0\n",
    "    mx_tag = None\n",
    "    for tag, cnt in candidate_suffs[suff].items():\n",
    "        if mx < cnt:\n",
    "            mx_tag = tag\n",
    "            mx = cnt\n",
    "        sm += cnt\n",
    "    score = mx/sm\n",
    "    suff_scores[suff] = score, mx_tag\n",
    "    \n",
    "def get_pred(word):\n",
    "    best_pref=None\n",
    "    best_pref_score = None\n",
    "    pred_pref = None\n",
    "    best_suff=None\n",
    "    best_suff_score = None\n",
    "    suffs = []\n",
    "    prefs = get_prefs(word)\n",
    "    suffs = get_suffs(word)\n",
    "    \n",
    "    for pref in prefs:\n",
    "        if (pref not in pref_scores):\n",
    "            continue\n",
    "        if (best_pref == None):\n",
    "            best_pref = pref\n",
    "            best_pref_score = pref_scores[pref][0]\n",
    "            pred_pref = pref_scores[pref][1]\n",
    "            continue\n",
    "        if (best_pref_score < pref_scores[pref][0]):\n",
    "            best_pref = pref\n",
    "            best_pref_score = pref_scores[pref][0]\n",
    "            pred_pref = pref_scores[pref][1]\n",
    "    \n",
    "    for suff in suffs:\n",
    "        if (suff not in suff_scores):\n",
    "            continue\n",
    "        if (best_suff == None):\n",
    "            best_suff = suff\n",
    "            best_suff_score = suff_scores[suff][0]\n",
    "            pred_suff = suff_scores[suff][1]\n",
    "            continue\n",
    "        if (best_suff_score < suff_scores[suff][0]):\n",
    "            best_suff = suff\n",
    "            best_suff_score = suff_scores[suff][0]\n",
    "            pred_suff = suff_scores[suff][1]\n",
    "            \n",
    "    if (best_pref_score == None):\n",
    "        if (best_suff_score == None):\n",
    "            pred = unk\n",
    "            # would never happen since atleast one letter always occurs\n",
    "        else:\n",
    "            pred = pred_suff\n",
    "    else:\n",
    "        if (best_suff_score == None):\n",
    "            pred = pred_pref\n",
    "        else:\n",
    "            if (best_pref_score < best_suff_score):\n",
    "                pred = pred_suff\n",
    "            else:\n",
    "                pred = pred_pref\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "336f322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate transition probabilities\n",
    "transition_probs = np.zeros((num_tags, num_tags))\n",
    "emission_probs = np.zeros((num_tags, num_words))\n",
    "start_probs = np.zeros(num_tags)\n",
    "for sent in train_data:\n",
    "    last = None\n",
    "    for word, tag in sent:\n",
    "        if word not in word2idx:\n",
    "            pred = get_pred(word)\n",
    "            if (last):\n",
    "                transition_probs[tag2idx[last], tag2idx[pred]]+=1\n",
    "            else:\n",
    "                start_probs[tag2idx[pred]]+=1\n",
    "            last = pred\n",
    "        else:\n",
    "            if (last):\n",
    "                transition_probs[tag2idx[last], tag2idx[tag]]+=1\n",
    "            else:\n",
    "                start_probs[tag2idx[tag]]+=1\n",
    "            last = tag\n",
    "        if word not in word2idx:\n",
    "            emission_probs[tag2idx[pred], word2idx[unk]] += 1\n",
    "        else:\n",
    "            emission_probs[tag2idx[tag], word2idx[word]] += 1\n",
    "            \n",
    "\n",
    "# normalize\n",
    "transition_probs = transition_probs/(transition_probs.sum(axis=1, keepdims=True)+1e-3)\n",
    "emission_probs = emission_probs/(emission_probs.sum(axis=1, keepdims=True)+1e-3)\n",
    "start_probs = start_probs/start_probs.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "955ebe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '[' in pref_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "851cac9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:39.490144Z",
     "iopub.status.busy": "2024-01-24T06:27:39.489123Z",
     "iopub.status.idle": "2024-01-24T06:27:39.495510Z",
     "shell.execute_reply": "2024-01-24T06:27:39.494649Z"
    },
    "papermill": {
     "duration": 0.028832,
     "end_time": "2024-01-24T06:27:39.498054",
     "exception": false,
     "start_time": "2024-01-24T06:27:39.469222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_tagger_util(untagged_sentence):\n",
    "    tagged_sentence = []\n",
    "    T = len(untagged_sentence)\n",
    "    viterbi_matrix = np.zeros((num_tags, T))\n",
    "    backpointer_matrix = np.zeros((num_tags, T), dtype=int)\n",
    "\n",
    "    # Initialization step\n",
    "    if untagged_sentence[0] not in word2idx:\n",
    "        viterbi_matrix[:, 0] = (start_probs+eps) *(emission_probs[:, word2idx[unk]]+eps)\n",
    "    else:\n",
    "        viterbi_matrix[:, 0] = (start_probs+eps) * (emission_probs[:, word2idx[untagged_sentence[0]]]+eps)\n",
    "\n",
    "    # Recursion step\n",
    "    for t in range(1, T):\n",
    "        for s in range(num_tags):\n",
    "            # Compute the maximum probability and corresponding backpointer\n",
    "            if untagged_sentence[t] not in word2idx:\n",
    "                probabilities = (viterbi_matrix[:, t - 1]+eps) * (transition_probs[:, s]+eps) * (emission_probs[s, word2idx[unk]]+eps)\n",
    "            else:\n",
    "                probabilities = (viterbi_matrix[:, t - 1]+eps) * (transition_probs[:, s]+eps) * (emission_probs[s, word2idx[untagged_sentence[t]]]+eps)\n",
    "            backpointer_matrix[s, t] = np.argmax(probabilities)\n",
    "            viterbi_matrix[s, t] = np.max(probabilities)\n",
    "\n",
    "    # Termination step\n",
    "    best_last_state = np.argmax(viterbi_matrix[:, T - 1])\n",
    "\n",
    "    # Backtrace to find the most probable state sequence\n",
    "    best_state_sequence = [best_last_state]\n",
    "    for t in range(T - 1, 0, -1):\n",
    "        best_last_state = backpointer_matrix[best_last_state, t]\n",
    "        best_state_sequence.insert(0, best_last_state)\n",
    "    \n",
    "    tagged_sentence = []\n",
    "    for i in range(T):\n",
    "        # if tags[best_state_sequence[i]] == unk:\n",
    "        #     tag = \"NN\"\n",
    "        # else:\n",
    "        #     tag = tags[best_state_sequence[i]]\n",
    "        if untagged_sentence[i] not in word2idx:\n",
    "            tag = get_pred(untagged_sentence[i])\n",
    "        else:\n",
    "            tag = tags[best_state_sequence[i]]\n",
    "        if tag == unk:\n",
    "            tag = default\n",
    "        tagged_sentence.append((untagged_sentence[i], tag))\n",
    "    return tagged_sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "999982a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## validation ##\n",
    "# corr = 0\n",
    "# total = 0\n",
    "# mistakes = []\n",
    "# for sent in val_data:\n",
    "#     untagged_sentence = []\n",
    "#     for word, tag in sent:\n",
    "#         if len(untagged_sentence) == 0:\n",
    "#             untagged_sentence.append(word.lower())\n",
    "#         else:\n",
    "#             untagged_sentence.append(word)\n",
    "#     pred = custom_tagger_util(untagged_sentence)\n",
    "#     cnt = 0\n",
    "#     for i in range(len(pred)):\n",
    "#         if pred[i][1] ==':-':\n",
    "#             cnt+=1\n",
    "#         else:\n",
    "#             cnt=0\n",
    "#         if cnt==2:\n",
    "#             # cut at this point\n",
    "#             pred2 = custom_tagger_util(untagged_sentence[i:])\n",
    "#             pred = pred[:i]+pred2\n",
    "#             break\n",
    "        \n",
    "#     cnt = 0\n",
    "#     temp = []\n",
    "#     for i in range(len(sent)):\n",
    "#         total+=1\n",
    "#         assert(sent[i][0] == pred[i][0])\n",
    "#         if (sent[i][1] == pred[i][1]):\n",
    "#             corr+=1\n",
    "#         else:\n",
    "#             cnt+=1\n",
    "#         temp.append((sent[i][0], sent[i][1], pred[i][1]))\n",
    "#     mistakes.append((cnt, temp))\n",
    "# mistakes = list(reversed(sorted(mistakes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16445a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mistakes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e12c902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:39.346432Z",
     "iopub.status.busy": "2024-01-24T06:27:39.345969Z",
     "iopub.status.idle": "2024-01-24T06:27:39.352465Z",
     "shell.execute_reply": "2024-01-24T06:27:39.351514Z"
    },
    "papermill": {
     "duration": 0.029691,
     "end_time": "2024-01-24T06:27:39.355084",
     "exception": false,
     "start_time": "2024-01-24T06:27:39.325393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = {'id': [], 'tagged_sentence' : []} # dictionary to store tag predictions\n",
    "# NOTE ---> ensure that tagged_sentence's corresponing 'id' is same as 'id' of corresponding 'untagged_sentence' in training data\n",
    "def store_submission(sent_id, tagged_sentence):\n",
    "    global submission\n",
    "    if(sent_id in list(submission['id'])):\n",
    "        return\n",
    "    submission['id'].append(sent_id)\n",
    "    submission['tagged_sentence'].append(tagged_sentence)\n",
    "    \n",
    "def clear_submission():\n",
    "    global submission\n",
    "    submission = {'id': [], 'tagged_sentence' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6e61b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:39.536647Z",
     "iopub.status.busy": "2024-01-24T06:27:39.535871Z",
     "iopub.status.idle": "2024-01-24T06:27:39.810083Z",
     "shell.execute_reply": "2024-01-24T06:27:39.808451Z"
    },
    "papermill": {
     "duration": 0.297769,
     "end_time": "2024-01-24T06:27:39.814010",
     "exception": false,
     "start_time": "2024-01-24T06:27:39.516241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:21<00:00, 187.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for sent_id in tqdm(list(test_data.keys())):\n",
    "    sent = list(reversed(test_data[sent_id]))\n",
    "    sent[0] = sent[0].lower()\n",
    "    tagged_sentence = custom_tagger_util(sent)\n",
    "    cnt = 0\n",
    "    for i in range(len(tagged_sentence)):\n",
    "        if tagged_sentence[i][1] ==':-':\n",
    "            cnt+=1\n",
    "        else:\n",
    "            cnt=0\n",
    "        if cnt==2:\n",
    "            # cut at this point\n",
    "            tagged_sentence2 = custom_tagger_util(sent[i:])\n",
    "            tagged_sentence = tagged_sentence[:i]+tagged_sentence2\n",
    "            break\n",
    "        \n",
    "    store_submission(sent_id, list(reversed(tagged_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0d2547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T06:27:39.855912Z",
     "iopub.status.busy": "2024-01-24T06:27:39.855380Z",
     "iopub.status.idle": "2024-01-24T06:27:39.995303Z",
     "shell.execute_reply": "2024-01-24T06:27:39.994062Z"
    },
    "papermill": {
     "duration": 0.16399,
     "end_time": "2024-01-24T06:27:39.998445",
     "exception": false,
     "start_time": "2024-01-24T06:27:39.834455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'data/submission_rev.csv'\n",
    "if (os.path.exists(path)):\n",
    "    os.remove(path)\n",
    "pd.DataFrame(submission).to_csv(path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7557019,
     "sourceId": 67975,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.613679,
   "end_time": "2024-01-24T06:27:40.841939",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-24T06:27:18.228260",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
